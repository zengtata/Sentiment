{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Environment Setup & Imports",
   "id": "6409103ebe2eb5cc"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T16:20:34.544704Z",
     "start_time": "2025-02-06T16:20:34.532690Z"
    }
   },
   "source": [
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "import optuna\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from transformers import (\n",
    "    DistilBertTokenizer,\n",
    "    DistilBertForSequenceClassification,\n",
    "    DistilBertConfig,\n",
    "    get_scheduler\n",
    ")\n",
    "from tqdm.auto import tqdm"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T16:20:34.607478Z",
     "start_time": "2025-02-06T16:20:34.593481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.backends.cudnn.benchmark = True  # Enable CuDNN optimizations"
   ],
   "id": "e02349260c79db83",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Data Loading and Preprocessing",
   "id": "eeafa6e5637ce10"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T16:20:37.012674Z",
     "start_time": "2025-02-06T16:20:34.611482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('datasets/all_it_jobs.csv')\n",
    "columns_to_keep = ['review_text', 'sentiment']\n",
    "df = df[columns_to_keep].dropna(subset=['review_text'])\n",
    "\n",
    "label_map = {\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2}\n",
    "df['label'] = df['sentiment'].map(label_map)"
   ],
   "id": "d5403caa82ef724c",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T16:20:53.793410Z",
     "start_time": "2025-02-06T16:20:53.654371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_sampled = (df.groupby(\"sentiment\")\n",
    "              .sample(n=500, random_state=42, replace=True)\n",
    "              .reset_index(drop=True))"
   ],
   "id": "9b980623f9de5ec2",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T16:20:54.468717Z",
     "start_time": "2025-02-06T16:20:54.449720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Diagnostics: print sample reviews before cleaning\n",
    "print(\"=== Sample reviews (raw) ===\")\n",
    "print(df_sampled['review_text'].head(3).to_list())"
   ],
   "id": "69bcb56791168eb1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample reviews (raw) ===\n",
      "['depends on teams avoid proddev bonuses are good on time salary other benefits like good location depends on teams avoid proddev rude senior management', 'do not expect more than 15 of hike while joining company provides the required benefits to the employees like all other big companies do if you are looking for 2040 percent of hike while joining cgi you are not a right candidate for them even though you are very good talented candidate if you negotiate a lot they can give you not more than 15 hike from your current ctc which is ridiculous', 'disrespectful and ancient generally nice people dinosaur it retro 1980s good for understanding how things shouldnt be done secretive great if you want to get in to 1960s spy work james bond stylebletchley park triplicate paper lack of training or when training is provided its interupted no investment in it everything is done on a shoe string']\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T16:20:56.788973Z",
     "start_time": "2025-02-06T16:20:56.769386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ],
   "id": "c8d3424c5720be33",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T16:20:57.870794Z",
     "start_time": "2025-02-06T16:20:57.812704Z"
    }
   },
   "cell_type": "code",
   "source": "df_sampled['cleaned_review'] = df_sampled['review_text'].apply(clean_text)",
   "id": "648972b1e739bf6c",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T16:20:58.483508Z",
     "start_time": "2025-02-06T16:20:58.468514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Diagnostics: print sample reviews after cleaning\n",
    "print(\"\\n=== Sample reviews (cleaned) ===\")\n",
    "print(df_sampled['cleaned_review'].head(3).to_list())"
   ],
   "id": "a4730d51069f626c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample reviews (cleaned) ===\n",
      "['depends on teams avoid proddev bonuses are good on time salary other benefits like good location depends on teams avoid proddev rude senior management', 'do not expect more than 15 of hike while joining company provides the required benefits to the employees like all other big companies do if you are looking for 2040 percent of hike while joining cgi you are not a right candidate for them even though you are very good talented candidate if you negotiate a lot they can give you not more than 15 hike from your current ctc which is ridiculous', 'disrespectful and ancient generally nice people dinosaur it retro 1980s good for understanding how things shouldnt be done secretive great if you want to get in to 1960s spy work james bond stylebletchley park triplicate paper lack of training or when training is provided its interupted no investment in it everything is done on a shoe string']\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Optimized Tokenization with Shorter Sequence Length",
   "id": "2e50811affed0b39"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T16:21:00.787880Z",
     "start_time": "2025-02-06T16:21:00.775801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_data(df, max_length=256):\n",
    "    \"\"\"Batch tokenization with optimized settings\"\"\"\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    return tokenizer(\n",
    "        text=df['cleaned_review'].tolist(),\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt',\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=False\n",
    "    )"
   ],
   "id": "203326cb1a02800d",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T16:21:04.287166Z",
     "start_time": "2025-02-06T16:21:01.304251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized = tokenize_data(df_sampled)\n",
    "input_ids = tokenized['input_ids']\n",
    "attention_mask = tokenized['attention_mask']\n",
    "labels = torch.tensor(df_sampled['label'].values, dtype=torch.long)"
   ],
   "id": "53d4bc794eb27d3b",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. Optimized Data Splitting",
   "id": "3179e495110c1592"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T16:21:04.302316Z",
     "start_time": "2025-02-06T16:21:04.292318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def stratified_split(inputs, masks, labels, test_size=0.3):\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=SEED)\n",
    "    train_idx, temp_idx = next(sss.split(inputs, labels))\n",
    "    return (inputs[train_idx], masks[train_idx], labels[train_idx]), \\\n",
    "           (inputs[temp_idx], masks[temp_idx], labels[temp_idx])"
   ],
   "id": "3b1357c714356446",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T16:21:04.814863Z",
     "start_time": "2025-02-06T16:21:04.791882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "(train_inputs, train_masks, train_labels), (temp_inputs, temp_masks, temp_labels) = stratified_split(input_ids, attention_mask, labels)\n",
    "(val_inputs, val_masks, val_labels), (test_inputs, test_masks, test_labels) = stratified_split(temp_inputs, temp_masks, temp_labels, test_size=0.5)"
   ],
   "id": "48c0e460ba215dc8",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T16:21:05.682987Z",
     "start_time": "2025-02-06T16:21:05.578479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ],
   "id": "667fd6c77306813c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5. Optimized Training Utilities",
   "id": "e49f8ef17d191ca8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T16:21:07.413529Z",
     "start_time": "2025-02-06T16:21:07.397527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_dataloader(inputs, masks, labels, batch_size, shuffle=False):\n",
    "    \"\"\"Ultra-fast DataLoader configuration\"\"\"\n",
    "    return DataLoader(\n",
    "        TensorDataset(inputs, masks, labels),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "        prefetch_factor=2\n",
    "    )"
   ],
   "id": "5e6143d619092567",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T16:21:08.533704Z",
     "start_time": "2025-02-06T16:21:08.513704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def validate(model, val_loader):\n",
    "    \"\"\"Batch-wise validation with mixed precision\"\"\"\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad(), torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "        for batch in val_loader:\n",
    "            inputs, masks, lbls = [t.to(device, non_blocking=True) for t in batch]\n",
    "            logits = model(inputs, attention_mask=masks).logits\n",
    "            all_preds.extend(logits.argmax(dim=-1).cpu().numpy())\n",
    "            all_labels.extend(lbls.cpu().numpy())\n",
    "    return accuracy_score(all_labels, all_preds)\n"
   ],
   "id": "70b0aa962b1bc7b6",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6. Optimized Optuna Objective Function",
   "id": "80d0c7cb9421a108"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T16:21:10.651255Z",
     "start_time": "2025-02-06T16:21:10.623419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Hyper-optimized objective function with early pruning\"\"\"\n",
    "    params = {\n",
    "        'lr': trial.suggest_float('lr', 1e-5, 5e-5, log=True),\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 1e-6, 1e-4, log=True),\n",
    "        'num_epochs': trial.suggest_int('num_epochs', 5, 10),\n",
    "        'hidden_dropout': trial.suggest_float('hidden_dropout', 0.2, 0.4),\n",
    "        'attention_dropout': trial.suggest_float('attention_dropout', 0.2, 0.4),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [32, 64]),\n",
    "        'grad_clip': trial.suggest_float('grad_clip', 0.5, 1.5),\n",
    "        'grad_accum_steps': trial.suggest_int('grad_accum_steps', 1, 2)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n--- Starting trial with params: {params} ---\")\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = create_dataloader(train_inputs, train_masks, train_labels, \n",
    "                                     params['batch_size'], shuffle=True)\n",
    "    val_loader = create_dataloader(val_inputs, val_masks, val_labels, \n",
    "                                   params['batch_size'])\n",
    "\n",
    "    # Model setup\n",
    "    config = DistilBertConfig.from_pretrained(\n",
    "        'distilbert-base-uncased',\n",
    "        num_labels=3,\n",
    "        hidden_dropout_prob=params['hidden_dropout'],\n",
    "        attention_probs_dropout_prob=params['attention_dropout']\n",
    "    )\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    config=config\n",
    ").to(device)\n",
    "    \n",
    "    # Optimizer setup\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=params['lr'], \n",
    "                            weight_decay=params['weight_decay'])\n",
    "    total_steps = (len(train_loader) // params['grad_accum_steps']) * params['num_epochs']\n",
    "    scheduler = get_scheduler('linear', optimizer, \n",
    "                              num_warmup_steps=int(total_steps*0.1), \n",
    "                              num_training_steps=total_steps)\n",
    "\n",
    "    # Training loop\n",
    "    scaler = torch.cuda.amp.GradScaler() \n",
    "    best_acc = 0\n",
    "    for epoch in range(params['num_epochs']):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        for step, batch in enumerate(train_loader):\n",
    "            inputs, masks, lbls = [t.to(device, non_blocking=True) for t in batch]\n",
    "            \n",
    "            with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                outputs = model(inputs, attention_mask=masks, labels=lbls)\n",
    "                loss = outputs.loss / params['grad_accum_steps']\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            if (step + 1) % params['grad_accum_steps'] == 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), params['grad_clip'])\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                scheduler.step()\n",
    "        \n",
    "        # Early validation and pruning\n",
    "        val_acc = validate(model, val_loader)\n",
    "        print(f\"Trial {trial.number}, Epoch {epoch+1}/{params['num_epochs']} - Val Acc: {val_acc:.4f}\")\n",
    "        trial.report(val_acc, epoch)\n",
    "        if trial.should_prune():\n",
    "            print(\"Trial pruned!\")\n",
    "            raise optuna.TrialPruned()\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "\n",
    "    print(f\"Trial {trial.number} finished with best validation accuracy: {best_acc:.4f}\")\n",
    "    return best_acc"
   ],
   "id": "51d5627c21a10994",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 7. Parallelized Optuna Study",
   "id": "101ee7e28f13cf75"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-02-06T16:21:12.557253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=1)\n",
    ")\n",
    "study.optimize(objective, n_trials=20, n_jobs=2, show_progress_bar=True)"
   ],
   "id": "48736e34f5bfa83",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-06 16:21:12,561] A new study created in memory with name: no-name-7a22356b-fa6a-407d-875d-bfc72f5826f8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30042506827546178d4b4afce754de43"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting trial with params: {'lr': 2.295679162486461e-05, 'weight_decay': 1.2257352124341086e-06, 'num_epochs': 10, 'hidden_dropout': 0.2175567299478534, 'attention_dropout': 0.2190715109748077, 'batch_size': 64, 'grad_clip': 0.9405184584750129, 'grad_accum_steps': 1} ---\n",
      "\n",
      "--- Starting trial with params: {'lr': 2.3593578994251797e-05, 'weight_decay': 7.75963334522764e-06, 'num_epochs': 9, 'hidden_dropout': 0.3825242272843598, 'attention_dropout': 0.35805707750424864, 'batch_size': 32, 'grad_clip': 1.0447225346682156, 'grad_accum_steps': 1} ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\KomPhone\\AppData\\Local\\Temp\\ipykernel_344\\1560113495.py:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "try:\n",
    "    import optuna.visualization as vis\n",
    "    vis.plot_optimization_history(study).show()\n",
    "except Exception as e:\n",
    "    print(\"Visualization failed:\", e)"
   ],
   "id": "22e6576e28f5a57e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 8. Final Training with Best Parameters",
   "id": "c40345de9279991b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T16:20:41.415330Z",
     "start_time": "2025-02-02T08:25:21.035035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_params = study.best_params.copy()\n",
    "print(\"\\nBest Hyperparameters Found:\")\n",
    "print(best_params)"
   ],
   "id": "c06d3cd55a41385a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'lr': 0.0004138040112561013, 'weight_decay': 8.200518402245835e-06, 'num_epochs': 5, 'hidden_dropout': 0.3736932106048628, 'attention_dropout': 0.27606099749584057}\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create DataLoaders\n",
    "train_loader = create_dataloader(train_inputs, train_masks, train_labels, \n",
    "                               best_params['batch_size'], shuffle=True)\n",
    "val_loader = create_dataloader(val_inputs, val_masks, val_labels, \n",
    "                             best_params['batch_size'])\n",
    "test_loader = create_dataloader(test_inputs, test_masks, test_labels, \n",
    "                              best_params['batch_size'])"
   ],
   "id": "ad28354941e3c450"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T16:20:41.416322900Z",
     "start_time": "2025-02-02T08:25:23.678657Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 22,
   "source": [
    "# Model initialization\n",
    "config = DistilBertConfig.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=3,\n",
    "    hidden_dropout_prob=best_params['hidden_dropout'],\n",
    "    attention_probs_dropout_prob=best_params['attention_dropout']\n",
    ")\n",
    "model = DistilBertForSequenceClassification(config).to(device)"
   ],
   "id": "37e91ef73113d7f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Optimizer setup\n",
    "optimizer = optim.AdamW(model.parameters(), lr=best_params['lr'], \n",
    "                      weight_decay=best_params['weight_decay'])\n",
    "total_steps = (len(train_loader) // best_params['grad_accum_steps']) * best_params['num_epochs']\n",
    "scheduler = get_scheduler('linear', optimizer, \n",
    "                        num_warmup_steps=int(total_steps*0.1), \n",
    "                        num_training_steps=total_steps)"
   ],
   "id": "9ee6866256aed1ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 9. Optimized Training Loop with Mixed Precision",
   "id": "6d4cb31e521f9242"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T16:20:41.416322900Z",
     "start_time": "2025-02-02T08:25:23.757535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 9. Optimized Training Loop with Mixed Precision (Fixed)\n",
    "def optimized_train(model, train_loader, optimizer, scheduler, params):\n",
    "    \"\"\"Ultra-efficient training loop with all optimizations\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    for step, batch in enumerate(tqdm(train_loader, desc=\"Training\")):  # Fixed: Added step counter\n",
    "        inputs, masks, lbls = [t.to(device, non_blocking=True) for t in batch]\n",
    "\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "            outputs = model(inputs, attention_mask=masks, labels=lbls)\n",
    "            loss = outputs.loss / params['grad_accum_steps']\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step + 1) % params['grad_accum_steps'] == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), params['grad_clip'])\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "\n",
    "        total_loss += loss.item() * params['grad_accum_steps']\n",
    "\n",
    "    return total_loss / len(train_loader)"
   ],
   "id": "928b4e9863a84e10",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 10. Early Stopped Training Execution",
   "id": "f295442e0351c588"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T16:20:41.416322900Z",
     "start_time": "2025-02-02T08:25:23.830535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "best_val_acc = 0\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(best_params['num_epochs']):\n",
    "    train_loss = optimized_train(model, train_loader, optimizer, scheduler, best_params)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    val_acc = validate(model, val_loader)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Val Acc = {val_acc:.4f}\")\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_uncased_bert_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= 3:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break"
   ],
   "id": "c3eef35da7192509",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Training Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss', color='blue', marker='o')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_accuracies, label='Validation Accuracy', color='green', marker='o')\n",
    "plt.title('Validation Accuracy Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "ea846f834d525673"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Final Evaluation",
   "id": "5beb01ca6e4cf264"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def evaluate_with_confusion_matrix(model, test_loader):\n",
    "    \"\"\"Evaluate model and generate confusion matrix\"\"\"\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad(), torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "        for batch in test_loader:\n",
    "            inputs, masks, lbls = [t.to(device, non_blocking=True) for t in batch]\n",
    "            logits = model(inputs, attention_mask=masks).logits\n",
    "            all_preds.extend(logits.argmax(dim=-1).cpu().numpy())\n",
    "            all_labels.extend(lbls.cpu().numpy())\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Final Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    return cm, accuracy"
   ],
   "id": "cd6bb30a2bf40ca9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_uncased_bert_model.pth'))"
   ],
   "id": "9df85371ad6a1ef5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Evaluate and plot confusion matrix\n",
    "cm, test_accuracy = evaluate_with_confusion_matrix(model, test_loader)"
   ],
   "id": "2b444f70850c4127"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot confusion matrix using Seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Negative', 'Neutral', 'Positive'], \n",
    "            yticklabels=['Negative', 'Neutral', 'Positive'])\n",
    "plt.title(f'Confusion Matrix (Test Accuracy: {test_accuracy:.2%})')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ],
   "id": "e430598499644bc6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2987b3e3669375d4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
